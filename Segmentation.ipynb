{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from SMM.smm_io.Scan import Scan\n",
    "from SMM.smm_io.ATF import load_gal\n",
    "\n",
    "from skimage.filters import *\n",
    "from skimage.morphology import *\n",
    "from skimage.feature import *\n",
    "from skimage.segmentation import *\n",
    "from skimage.transform import *\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage import draw as skdraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan(50001918, 532nm, Standard Green)\n"
     ]
    }
   ],
   "source": [
    "scan = Scan.load_tif('/Volumes/RMW_3/RBD_Panel/SMM-opt/50001918_2020-12-30_S46_A1.tif')[0]\n",
    "print(scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koehlerchemmodeling/PycharmProjects/SMM-Analysis/SMM/smm_io/ATF.py:14: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  return pd_object.str.upper().str.replace('.', '')\n"
     ]
    }
   ],
   "source": [
    "gal = load_gal('/Volumes/RMW_3/Compact-Set1.gal', map_blocks=True)\n",
    "gal.ID\n",
    "ids = gal.ID.str.extract(r'(\\d+)-([A-P])(\\d+)\\Z').convert_dtypes()\n",
    "ids.columns = ['Plate', 'Row', 'Column']\n",
    "sentinels = gal[(ids.Plate=='30') & (ids.Row.str.contains(r'[I-P]'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impose_grid(pil, gal, xpos, ypos, res):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for _, x, y, r in gal[['X', 'Y', 'DIA']].itertuples():\n",
    "        x = (x-xpos)//res\n",
    "        y = (y-ypos)//res\n",
    "        r = (r/2)//res\n",
    "        draw.ellipse((x-r, y-r, x+r, y+r), outline='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask(scan, gal):\n",
    "    mask = np.zeros(scan.data.shape)\n",
    "    xpos = scan.x_offset\n",
    "    ypos = scan.y_offset\n",
    "    res = scan.resolution\n",
    "    shape = scan.data.shape\n",
    "    indices = []\n",
    "    for _, x, y, r in gal[['X', 'Y', 'DIA']].itertuples():\n",
    "        x = (x-xpos)/res\n",
    "        y = (y-ypos)/res\n",
    "        r = (r/2)/res\n",
    "        indices.append(skdraw.disk((y, x), r, shape=shape))\n",
    "    r = np.concatenate([n[0] for n in indices])\n",
    "    c = np.concatenate([n[1] for n in indices])\n",
    "    rmin = r.min()\n",
    "    cmin = c.min()\n",
    "    r -= rmin\n",
    "    c -= cmin\n",
    "    output = np.zeros((r.max()+1, c.max()+1), dtype=bool)\n",
    "    output[r,c] = 1\n",
    "    return output, rmin, cmin\n",
    "\n",
    "# TODO magic numbers based on circle area\n",
    "def register_array(scan, sentinels):\n",
    "    lower_border = 8/9*scan.data.shape[0]\n",
    "    thresh = scan.data[0:lower_border] > (threshold_local(scan.data[0:lower_border], 35, method='mean') * 2)\n",
    "    thresh = binary_opening(thresh)\n",
    "    remove_small_objects(thresh, 50, in_place=True)\n",
    "    thresh = distance_transform_edt(~thresh)**2\n",
    "    mask = make_mask(scan, sentinels)\n",
    "\n",
    "    d2, rmin, cmin = match_template(thresh, ~mask)\n",
    "    r, c = np.unravel_index(np.argmax(d2), d2.shape)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = scan.data[300:6400] > (threshold_local(scan.data[300:6400], 35, method='mean') * 2)\n",
    "thresh = binary_opening(thresh)\n",
    "remove_small_objects(thresh, 50, in_place=True)\n",
    "mask = make_mask(scan, sentinels)\n",
    "\n",
    "d2 = match_template(thresh, mask)\n",
    "r, c = np.unravel_index(np.argmax(d2), d2.shape)\n",
    "\n",
    "out1 = Image.fromarray(d2*255).convert('RGB')\n",
    "draw = ImageDraw.Draw(out1)\n",
    "draw.ellipse([c-5, r-5, c+5, r+5], fill='red')\n",
    "out1.show()\n",
    "\n",
    "out2 = Image.fromarray(scan.data).convert('RGB')\n",
    "draw = ImageDraw.Draw(out2)\n",
    "draw.rectangle([c, r+300, c+mask.shape[1], 300+r+mask.shape[0]], outline='red')\n",
    "out2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.ndimage import label as ndi_label\n",
    "from skimage import transform as tf\n",
    "from skimage.measure import regionprops\n",
    "from skimage.morphology import binary_opening as opening\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=4)\n",
    "def _find_bright_regions(scan, channel):\n",
    "    if channel not in scan.channels:\n",
    "        raise ValueError(\"Invalid channel %s for guide detection\" % channel)\n",
    "    im = scan[channel]\n",
    "    im = im[0:int(5 * im.shape[0] / 6)]\n",
    "    binary_image = im > (im.mean() * 1.3)  # TODO Implement a less arbitrary threshold for creating the binary image\n",
    "    binary_image = opening(opening(binary_image))\n",
    "    labeled_image, _ = ndi_label(binary_image)\n",
    "    return regionprops(labeled_image, coordinates='rc')\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=8)\n",
    "def get_spots(scan, channel, radius):\n",
    "    radius /= scan.resolution\n",
    "    regions = _find_bright_regions(scan, channel)\n",
    "    result = [i.centroid for i in regions if\n",
    "              3.14*(radius/2)**2 < i.area < 3.14*(radius*2)**2 and\n",
    "              i.equivalent_diameter > radius > i.equivalent_diameter/4 and i.eccentricity < 0.8]\n",
    "    if len(result) == 0:\n",
    "        raise RuntimeError(\"No spots could be detected in channel %s\" % channel)\n",
    "    return cKDTree(np.array(result) * scan.resolution + scan.offset)\n",
    "\n",
    "\n",
    "class Alignment:\n",
    "    _ARRAY_TRANSFORMATIONS = [('euclidean', 10)] * 50 + [('similarity', 4)] * 50\n",
    "    _BLOCK_TRANSFORMATIONS = [('euclidean', 3)] * 50 + [('affine', 2)] * 50\n",
    "\n",
    "    def __init__(self, gal, scan, guide_names):\n",
    "        if scan.image.format != \"TIFF\":\n",
    "            raise ValueError(\"Alignment to non-TIFF images is not supported\")\n",
    "        if len(guide_names) == 0:\n",
    "            raise ValueError(\"Guide names must be provided in at least one channel\")\n",
    "        if set(guide_names) - set(scan.channels):\n",
    "            raise ValueError(\"Channel %s doesn't exist in the scan\" % (set(guide_names)-set(scan.channels)))\n",
    "\n",
    "        self.aligned = pd.DataFrame(index=gal.index, columns=['Y', 'X', 'Radius'])\n",
    "        self.gal = gal\n",
    "        self.scan = scan\n",
    "        self.guides = guide_names\n",
    "\n",
    "    def _current_position(self):\n",
    "        current = self.gal[['Block', 'Name', 'ID', 'Y', 'X', 'Radius']].copy()\n",
    "        current.update(self.aligned)\n",
    "        return current\n",
    "\n",
    "    def approximate(self):\n",
    "        gal = self._current_position()\n",
    "        xform = approximate_placement(gal, self.scan, self.guides)\n",
    "        self.aligned[['Y', 'X']] = xform(gal[['Y', 'X']])\n",
    "\n",
    "    def as_array(self):\n",
    "        gal = self._current_position()\n",
    "        xform, distance = icp_register(gal, self.scan, self.guides, Alignment._ARRAY_TRANSFORMATIONS)\n",
    "        if sum(distance < 80) / len(distance) < 0.8:\n",
    "            raise RuntimeError(\"Inadequate matching (%s/%s)\" % (sum(distance < 80), len(distance)))\n",
    "        if xform.rotation > 3 or abs(1-xform.scale[0])>0.05:\n",
    "            raise RuntimeError(\"Unreasonable transformation\")\n",
    "        self.aligned[['Y', 'X']] = xform(gal[['Y', 'X']])\n",
    "\n",
    "    def as_blocks(self):\n",
    "        gal = self._current_position()\n",
    "        failed = []\n",
    "        for i, block in gal.groupby(\"Block\"):\n",
    "            try:\n",
    "                xform, distance = icp_register(block, self.scan, self.guides, Alignment._BLOCK_TRANSFORMATIONS)\n",
    "                if sum(distance < 80) / len(distance) < 0.8:\n",
    "                    raise RuntimeError(\"Inadequate matching (%s/%s)\" % (sum(distance < 80), len(distance)))\n",
    "                if abs(1-xform.scale[0]) > 0.01 or xform.rotation > 3:\n",
    "                    raise RuntimeError(\"Unreasonable transformation\")\n",
    "                self.aligned.loc[block.index, ['Y', 'X']] = xform(block[['Y', 'X']])\n",
    "\n",
    "            except (ValueError, RuntimeError) as ex:\n",
    "                failed.append(\"Failed block %s: %s\" % (i, str(ex)))\n",
    "        if failed:\n",
    "            raise RuntimeError('\\n'.join(failed))\n",
    "\n",
    "\n",
    "def approximate_placement(gal, scan, guide_names):\n",
    "    radius = gal.Radius.mean()\n",
    "    gal = gal.loc[gal.matching('|'.join(guide_names.values())), ['Y', 'X']].values\n",
    "    if len(gal) < 4: raise ValueError(\"Guide names do not match to rows in the array\")\n",
    "    scan_points = np.vstack(get_spots(scan, channel, radius).data for channel in guide_names)\n",
    "    if len(scan_points) < 4: raise RuntimeError(\"Guide spots cannot be detected in scan\")\n",
    "    array_height, array_width = np.ptp(gal, 0)*1.01\n",
    "    bottom_edge, right_edge = np.max(scan_points, 0)\n",
    "    best_point = np.min(gal, 0)\n",
    "    best_size = 0\n",
    "    y_positions = np.sort(scan_points[:,0])\n",
    "    for y_position in y_positions:\n",
    "        y_dist = scan_points[:, 0] - y_position\n",
    "        covered_points = scan_points[(0 <= y_dist) & (y_dist <= array_height)]\n",
    "        x_positions = np.sort(covered_points[:, 1])\n",
    "        for x_position in x_positions:\n",
    "            x_dist = covered_points[:, 1] - x_position\n",
    "            covered_count = ((0 <= x_dist) & (x_dist <= array_width)).sum()\n",
    "            if covered_count > best_size:\n",
    "                best_size = covered_count\n",
    "                best_point = np.array([y_position, x_position])\n",
    "            if x_position + array_width >= right_edge: break\n",
    "        if y_position + array_height >= bottom_edge: break\n",
    "    return tf.EuclideanTransform(translation=best_point - np.min(gal, 0))\n",
    "\n",
    "\n",
    "def icp_register(gal, scan, guides, transformations):\n",
    "    radius = gal.Radius.mean()\n",
    "    models = []; trees = []\n",
    "\n",
    "    # Pair the appropriate gal \"model\" points and the scan points (in the form of cKDTrees)\n",
    "    for channel, name in guides.items():\n",
    "        model = gal.loc[gal.matching(name), ['Y', 'X']].values.astype('float64')\n",
    "        tree = get_spots(scan, channel, radius)\n",
    "        if model.size != 0 and tree.data.size != 0:\n",
    "            models.append(model)\n",
    "            trees.append(tree)\n",
    "\n",
    "    if len(models) == 0:\n",
    "        raise RuntimeError(\"Pairing between guides and detected scan spots wasn't successful\")\n",
    "\n",
    "    # Estimate a transformation according to each instruction in the transformations sequence\n",
    "    xform = tf.AffineTransform()\n",
    "    for transform, fractional_limit in transformations:\n",
    "        xform += _register_closest_point(map(xform, models), trees, transform, radius * fractional_limit)\n",
    "    distance = np.concatenate([tree.query(xform(model))[0] for model, tree in zip(models, trees)])\n",
    "\n",
    "    return tf.AffineTransform(xform.params), distance\n",
    "\n",
    "\n",
    "def _register_closest_point(models, trees, ttype='euclidean', limit=np.inf):\n",
    "    # Pair the points between the models and the closest detected scan points\n",
    "    q = []\n",
    "    t = []\n",
    "    for model, scene in zip(models, trees):\n",
    "        d, i = scene.query(model)\n",
    "        keep = d <= limit\n",
    "        q.append(model[keep])\n",
    "        t.append(scene.data[i[keep]])\n",
    "    current_model = np.vstack(q)\n",
    "    matched_scene = np.vstack(t)\n",
    "    if len(current_model) < 4:\n",
    "        raise RuntimeError(\"Insufficient guide spot matching to scan\")\n",
    "\n",
    "    # Estimate the next best transform and update the current transform\n",
    "    return tf.estimate_transform(ttype, current_model, matched_scene)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
